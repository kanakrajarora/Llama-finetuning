# ğŸš€ Fine-Tuning LLaMA with LoRA on a Custom Dataset  

This repository contains code to fine-tune **LLaMA (LLaMA-2/3)** on a custom dataset using **LoRA (Low-Rank Adaptation)**. LoRA enables efficient fine-tuning of large language models while reducing GPU memory usage.  

---

## Video demonstration
https://youtu.be/ZYRiFmkdD6k

## ğŸ“Œ Features
- âœ… Fine-tunes **LLaMA-2 8B** or **LLaMA-3 7B** using Hugging Faceâ€™s Transformers and PEFT  
- âœ… Implements **LoRA (Low-Rank Adaptation)** for parameter-efficient fine-tuning  
- âœ… Runs on **Google Colab** with GPU support  
- âœ… Supports **custom dataset processing** (JSON/CSV format)  
- âœ… Saves the fine-tuned model and uploads it to **Hugging Face Model Hub**  

## âš™ï¸ Setup & Installation
### ğŸ›  1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/kanarajarora/Llama-finetuning.git
cd fine-tuning-llama-lora
```

### ğŸ“¦ 2ï¸âƒ£ Install Dependencies  
```bash
pip install -r requirements.txt
```

### ğŸ”‘ 3ï¸âƒ£ Authenticate Hugging Face
```bash
from huggingface_hub import notebook_login
notebook_login()
```
 
